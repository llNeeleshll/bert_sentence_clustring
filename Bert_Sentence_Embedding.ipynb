{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Sentence Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llNeeleshll/bert_sentence_clustring/blob/main/Bert_Sentence_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99FtkmPreeX4",
        "outputId": "360893ca-2acb-4636-ec90-1ec50aa395a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install kmeans-pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: kmeans-pytorch in /usr/local/lib/python3.6/dist-packages (0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONRICy0uegW8"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6ImTgi2epyb"
      },
      "source": [
        "class BertEmbeddings:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    \n",
        "    \n",
        "  def embed_text(self, text_to_embed):\n",
        "    \n",
        "    marked_text = \"[CLS] \" + text_to_embed + \" [SEP]\"\n",
        "    tokenized_text = self.tokenizer.tokenize(marked_text)\n",
        "    indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      outputs = self.model(tokens_tensor, segments_tensors)\n",
        "      # Evaluating the model will return a different number of objects based on \n",
        "      # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "      # becase we set `output_hidden_states = True`, the third item will be the \n",
        "      # hidden states from all layers. See the documentation for more details:\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2]\n",
        "      \n",
        "    # Concatenate the tensors for all layers. We use `stack` here to\n",
        "    # create a new dimension in the tensor.\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    \n",
        "    # Remove dimension 1, the \"batches\".\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "    # Swap dimensions 0 and 1.\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    # Stores the token vectors, with shape [31 x 768]\n",
        "    token_vecs_sum = []\n",
        "\n",
        "    # For each token in the sentence...\n",
        "    for token in token_embeddings:\n",
        "\n",
        "        # `token` is a [12 x 768] tensor\n",
        "\n",
        "        # Sum the vectors from the last four layers.\n",
        "        sum_vec = torch.sum(token[-4:], dim=0)\n",
        "        \n",
        "        # Use `sum_vec` to represent `token`.\n",
        "        token_vecs_sum.append(sum_vec)\n",
        "\n",
        "    total_vector_sum = torch.zeros([1,768])\n",
        "\n",
        "    for i in range(len(token_vecs_sum)):\n",
        "        total_vector_sum += token_vecs_sum[i]\n",
        "\n",
        "    return total_vector_sum\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp3ZhCRej_0X",
        "outputId": "4e7184e5-81c7-4b8f-a0ca-ce94ac858a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "be = BertEmbeddings()\n",
        "import numpy  as np\n",
        "x = [\"I hate it\",\n",
        "     \"I really love to play cricket\",\n",
        "     \"This is very bad. You should kill him\", \n",
        "     \"This is awesome, I am looking to work\"]\n",
        "\n",
        "#encoded_x = be.embed_text(x[1])\n",
        "l = [be.embed_text(x[i]) for i in range(0, len(x))]\n",
        "\n",
        "#print(encoded_x.shape)\n",
        "\n",
        "l = tuple(l)\n",
        "encoded_x = torch.stack((l), dim=0)\n",
        "print(encoded_x.data)\n",
        "print(encoded_x.shape)\n",
        "\n",
        "#et = be.embed_text(\"deposite money in a bank\")\n",
        "#et2 = be.embed_text(\"This is the best\")"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[  1.9738,  10.4972,  -5.3046,  ...,   5.5136,   3.6367,   6.2034]],\n",
            "\n",
            "        [[ 23.1837,   2.3267,  -2.1827,  ...,  -0.0416,  10.5470, -11.5288]],\n",
            "\n",
            "        [[  7.6840,   3.7987,   1.6742,  ...,  -0.6801,   5.2528,   1.1538]],\n",
            "\n",
            "        [[ 11.2275,   5.4036,  14.8448,  ..., -13.0721,   1.6352,   1.5287]]])\n",
            "torch.Size([4, 1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9J6TOkYl4LB",
        "outputId": "b0882c93-41ab-4309-d187-0c63316c650a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from kmeans_pytorch import kmeans\n",
        "\n",
        "cluster_ids_x, cluster_centers = kmeans(\n",
        "    X=encoded_x, num_clusters=2, distance='euclidean')\n",
        "\n",
        "print(cluster_ids_x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 2it [00:00, 159.52it/s, center_shift=0.000000, iteration=2, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cpu..\n",
            "tensor([1, 1, 1, 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia3utEf9aYvi"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the sentences \n",
        "\n",
        "sim = (1 - cosine(et, et2)) * 100\n",
        "from kmeans_pytorch import kmeans\n",
        "print(\"The similarity is : %.2f\" % sim, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfGD4sGAQvwq",
        "outputId": "835dde5b-b16d-4a57-ec56-a5ed60c2f1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from kmeans_pytorch import kmeans_predict\n",
        "\n",
        "ex = \"i dont like food\"\n",
        "ex = be.embed_text(ex)\n",
        "print(ex.shape)\n",
        "cluster_ids_y = kmeans_predict(\n",
        "    ex , cluster_centers, 'euclidean'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768])\n",
            "predicting on cpu..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-536d12395c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m cluster_ids_y = kmeans_predict(\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mex\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kmeans_pytorch/__init__.py\u001b[0m in \u001b[0;36mkmeans_predict\u001b[0;34m(X, cluster_centers, distance, device)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distance_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mchoice_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchoice_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAVdpdfpQ5kG"
      },
      "source": [
        "plt.figure(figsize=(4, 3), dpi=160)\n",
        "plt.scatter(x[:, 0], x[:, 1], c=cluster_ids_x, cmap='cool')\n",
        "plt.scatter(y[:, 0], y[:, 1], c=cluster_ids_y, cmap='cool', marker='X')\n",
        "plt.scatter(\n",
        "    cluster_centers[:, 0], cluster_centers[:, 1],\n",
        "    c='white',\n",
        "    alpha=0.6,\n",
        "    edgecolors='black',\n",
        "    linewidths=2\n",
        ")\n",
        "plt.axis([-1, 1, -1, 1])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QZa4aBQ9wVR",
        "outputId": "2b958c73-eb43-47e4-db6a-41d349a7896d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "s1 = torch.empty(0,3)\n",
        "s2 = torch.tensor([4,5,6])\n",
        "s2 = torch.stack((s1,s2), dim=0)\n",
        "\n",
        "print(s2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-35cdfa216943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [0, 3] at entry 0 and [3] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfPSFW00c_ru",
        "outputId": "f2ad5c9b-9e78-45b0-bf6f-b716dd0f5ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "be = BertEmbeddings()\n",
        "import numpy  as np\n",
        "x1 = [\"I hate it\",\n",
        "     \"I really love to play cricket\",\n",
        "     \"This is very bad. You should kill him\", \n",
        "     \"This is awesome, I am looking to work\"]\n",
        "\n",
        "#encoded_x = be.embed_text(x[1])\n",
        "l1 = [be.embed_text(x1[i]) for i in range(0, len(x1))]\n",
        "\n",
        "numy = np.array(l1)\n",
        "#print(encoded_x.shape)\n",
        "\n",
        "l1 = tuple(l1)\n",
        "encoded_x = torch.stack((l1), dim=0)\n",
        "print(encoded_x.data)\n",
        "print(encoded_x.shape)\n",
        "\n",
        "#et = be.embed_text(\"deposite money in a bank\")\n",
        "#et2 = be.embed_text(\"This is the best\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-a6a0b51f142c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnumy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(encoded_x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iryLo3xlBqdb",
        "outputId": "bc07251c-5c87-44c5-c61e-dc18b57c26ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(numy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-96b94dd58b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'numy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM2zS6aCegG3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}