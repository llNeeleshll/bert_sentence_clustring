{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Sentence Embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/llNeeleshll/bert_sentence_clustring/blob/main/Bert_Sentence_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99FtkmPreeX4",
        "outputId": "703a9e79-aabf-413a-f82e-3fce87075755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install kmeans-pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 18.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=950f16b4fa744dccecc22b34f28399cc01590f620b29a9ad7ca05a0f39579467\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting kmeans-pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/b5/c9/eb5b82e7e9741e61acf1aff70530a08810aa0c7e2272c534ff7a150fc5bd/kmeans_pytorch-0.3-py3-none-any.whl\n",
            "Installing collected packages: kmeans-pytorch\n",
            "Successfully installed kmeans-pytorch-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONRICy0uegW8"
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from scipy.spatial.distance import cosine\n",
        "import numpy  as np\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6ImTgi2epyb"
      },
      "source": [
        "class BertEmbeddings:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    \n",
        "  def embed_text(self, text_to_embed):\n",
        "    \n",
        "    marked_text = \"[CLS] \" + text_to_embed + \" [SEP]\"\n",
        "    tokenized_text = self.tokenizer.tokenize(marked_text)\n",
        "    indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      outputs = self.model(tokens_tensor, segments_tensors)\n",
        "      # Evaluating the model will return a different number of objects based on \n",
        "      # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "      # becase we set `output_hidden_states = True`, the third item will be the \n",
        "      # hidden states from all layers. See the documentation for more details:\n",
        "      # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "      hidden_states = outputs[2]\n",
        "      \n",
        "    # Concatenate the tensors for all layers. We use `stack` here to\n",
        "    # create a new dimension in the tensor.\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    \n",
        "    # Remove dimension 1, the \"batches\".\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "    # Swap dimensions 0 and 1.\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    # Stores the token vectors, with shape [31 x 768]\n",
        "    token_vecs_sum = []\n",
        "\n",
        "    # For whole sentence\n",
        "    token_vecs = hidden_states[-2][0]\n",
        "\n",
        "    # Calculate the average of all 22 token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "    # For each token in the sentence...\n",
        "    for token in token_embeddings:\n",
        "\n",
        "        # `token` is a [12 x 768] tensor\n",
        "\n",
        "        # Sum the vectors from the last four layers.\n",
        "        sum_vec = torch.sum(token[-4:], dim=0)\n",
        "        \n",
        "        # Use `sum_vec` to represent `token`.\n",
        "        token_vecs_sum.append(sum_vec)\n",
        "\n",
        "    total_vector_sum = torch.zeros([1,768])\n",
        "\n",
        "    for i in range(len(token_vecs_sum)):\n",
        "        total_vector_sum += token_vecs_sum[i]\n",
        "\n",
        "    return total_vector_sum\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp3ZhCRej_0X",
        "outputId": "2db5ef55-05c3-4c1d-8238-9f39693030d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "be = BertEmbeddings()\n",
        "\n",
        "x = [\"I hate it\",\n",
        "     \"I really love to play cricket\",\n",
        "     \"This is very bad. You should kill him\", \n",
        "     \"This is awesome, I am looking to work\"]\n",
        "\n",
        "#encoded_x = be.embed_text(x[1])\n",
        "l = [be.embed_text(x[i]) for i in range(0, len(x))]\n",
        "\n",
        "#print(encoded_x.shape)\n",
        "\n",
        "l = tuple(l)\n",
        "encoded_x = torch.stack((l), dim=0)\n",
        "print(encoded_x.data)\n",
        "print(encoded_x.shape)\n",
        "\n",
        "#et  = be.embed_text(\"deposite money in a bank\")\n",
        "#et2 = be.embed_text(\"This is the best\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0439,  0.6635, -0.1679,  ...,  0.2582,  0.1644,  0.3177],\n",
            "        [ 0.6989,  0.0863,  0.0043,  ..., -0.1464,  0.1625, -0.4249],\n",
            "        [ 0.0784,  0.1402, -0.0037,  ..., -0.0830,  0.1059,  0.0242],\n",
            "        [ 0.1594,  0.1144,  0.3340,  ..., -0.3674,  0.0539,  0.1564]])\n",
            "torch.Size([4, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9J6TOkYl4LB",
        "outputId": "88842d29-c4b2-41fb-e3a8-f2489e1fb61f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from kmeans_pytorch import kmeans\n",
        "\n",
        "cluster_ids_x, cluster_centers = kmeans(\n",
        "    X=encoded_x, num_clusters=2, distance='euclidean')\n",
        "\n",
        "print(cluster_ids_x)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[running kmeans]: 2it [00:00, 426.16it/s, center_shift=0.000000, iteration=2, tol=0.000100]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running k-means on cpu..\n",
            "tensor([0, 1, 0, 1])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1cUTuMTx3ln",
        "outputId": "1097ecb7-28c2-4a76-a187-72d6590551fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# read the email file\n",
        "df = pd.read_excel(\"sentiment_review.xlsx\")\n",
        "df.head()\n",
        "x = df.iloc[:,0].tolist()\n",
        "print(x[5])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This isn't the comedic Robin Williams, nor is it the quirky/insane Robin Williams of recent thriller fame. This is a hybrid of the classic drama without over-dramatization, mixed with Robin's new love of the thriller. But this isn't a thriller, per se. This is more a mystery/suspense vehicle through which Williams attempts to locate a sick boy and his keeper.<br /><br />Also starring Sandra Oh and Rory Culkin, this Suspense Drama plays pretty much like a news report, until William's character gets close to achieving his goal.<br /><br />I must say that I was highly entertained, though this movie fails to teach, guide, inspect, or amuse. It felt more like I was watching a guy (Williams), as he was actually performing the actions, from a third person perspective. In other words, it felt real, and I was able to subscribe to the premise of the story.<br /><br />All in all, it's worth a watch, though it's definitely not Friday/Saturday night fare.<br /><br />It rates a 7.7/10 from...<br /><br />the Fiend :.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFraNACLeP62",
        "outputId": "b41e60cb-f864-4ab2-c3e9-6a1e9dd9ad6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "# read the email file\n",
        "df = pd.read_excel(\"sentiment_review.xlsx\")\n",
        "x = df.iloc[:3,0].tolist()\n",
        "\n",
        "embeding_bert = BertEmbeddings()\n",
        "\n",
        "# r = embeding_bert.embed_text(\"Subject: here ' s a hot play in motion  homeland security investments  the terror attacks on the united states on september 11 , 20 ol have  changed  the security landscape for the foreseeable future . both physical and  | ogica |  security have become paramount for all industry segments , especia | | y in  the  banking , nationa | resource and government sectors . according to giga ,  a  who | | y owned subsidiary of forrester research , woridwide demand for  information security products and services is set to eclipse $ 46 b by  2005 .  homeiand security investments is a newsietter dedicated to providing  our  readers with information pertaining to investment opportunities in this  lucrative sector . as we know , events related to homeland security  happen  with lightning speed . what we as investors can do is position  ourselves in  such a way as to take advantage of the current trends and be ready to  capitalize on events which have yet to happen . homeland security  investments is here to heip our readers do just that .  with this in mind , it is with great excitement that we present vinoble ,  inc .  this stock is expected to do big things in both the near and | ong  terms .  symbol : vnbl . ob  current price : o . 08  short term target price : o . 35  12 month target price : 1 . 20  * * * why we believe vnbl . ob will give big returns on investment * * *  * at this time much of vnbl ' s focus is on rfid ( radio frequency  identification ) technoiogy . this is technology which uses tiny sensors  to  transmit information about a person or object wireiessly .  * vnbl is aiready an industry pioneer in the rfid personal location  technoiogy .  * vnbl is developing a form of rfid technology which allows companies  and  governments to wirelessly track their assets and resources . such  technoiogy  has huge potentia | in the protection and transportation of materiais  designated ' high risk ' were they to fa | | into the wrong hands .  * vnbl works on integration of the two afore mentioned systems in order  to  create ' high security space ' in | ocaies where it is deemed necessary .  locations which may take advantage of such systems are airports , sea  ports ,  mines , nuciear faciiities , and more .  * as with a | | stocks , news drives the short term price . fresh news has  made vnbl a hot buy .  news on vnbl  malibu , calif . - - ( business wire ) - - june 16 , 2 oo 5 - - vinoble , inc .  ( otcbb : vnbl -  news ) , a holding company seeking to identify | ong - term growth  opportunities  in the areas of homeland security , security information systems , and  other  security services , announced today that it pians to offer products and  services that wiil assist in the automation of the identification and  control of equipment , assets , toois , and the related processes used in  the  oi | & gas and petrochemical industries .  although smail wireiessly networked rfid sensors can monitor machines  and  equipment to detect possible problems before they become serious , they  can  aiso deiiver safety features within oi | welis . oi | maybe trapped in  different | ayers of rock , aiong with gas and water . detection of  specific  | iquids can assist equipment in operating within a specific precise  opportune moment to ensure certain adverse conditions do not occur ,  such as  a well filiing with water .  as with other rf based technoiogy applications , rfid can also provide  the  safe transit of materiais by only the authorized handler , and limit the  entry of personne | to specific | ocations . ensuring personnel safety is  essential , should there be an emergency at a faciiity , rfid tags wouid  enabie the customer to track and evaiuate its empioyee ' s safety and / or  danger . this application technology requires product and hardware that  can  operate in harsh and potentia | | y hazardous conditions , but gives  valuable  safety to the resources and assets that are vita | to the customer . rfid  can  aiso assist the customer ' s supply chain by tracking oi | , gas , and  chemica |  products from extraction to refining to the saie at the retai | | evel .  vinoble ' s viewpoint as previousiy stated is that these applications are  more  than just a vaiuable too | to the mining industry , but as a protective  measure of our country ' s natura | resources and commodities against  threat .  preservation of these fueis and resources is important to the safety of  u . s .  industry and economy .  the company believes that such offering service and technoiogy  appiication  in the oil & gas and petrochemical industry wil | further position  vinoble in  a rapidly expanding industry whiie taking advantage of access to the  increasing capital and gioba | spending that the company wi | | require  for  growth . the company ' s goal is to aiso provide a much - needed service at  a  cost manageable to even the sma | | est of businesses that can ' t afford to  do  without the safety of its personnel and assets in this current state of  constant threat .  this is outstanding news . the growth potential for this company is  exceptional . in an already hot industry , vnbl . ob stands out as a truiy  innovative pioneer . we see big things happening to this stock .  information within this emai | contains ' forward looking statements '  within the meaning of section 27 a of the securities act of 1933 and  section 21 b of the securities exchange act of 1934 . any statements that  express or involve discussions with respect to predictions ,  expectations , beliefs , pians , projections , objectives , goals ,  assumptions or  future  events or performance are not statements of historica | fact and may be  ' forward | ooking statements . ' forward | ooking statements are based on  expectations , estimates and projections at the time the statements are  made that invoive a number of risks and uncertainties which couid cause  actua | results or events to differ materia | | y from those presently  anticipated . forward looking statements in this action may be  identified  through the use of words such as ' projects ' , ' foresee ' , ' expects ' ,  ' wi | | , ' ' anticipates , ' ' estimates , ' ' beiieves , ' ' understands ' or  that by  statements indicating certain actions ' may , ' ' couid , ' or ' might ' occur .  as with many micro - cap stocks , today ' s company has additional risk  factors worth noting . those factors inciude : a limited operating  history ,  the company advancing cash to reiated parties and a shareholder on an  unsecured basis : one vendor , a related party through a majority  stockhoider , supplies ninety - seven percent of the company ' s raw  materiais :  reiiance on two customers for over fifty percent of their business and  numerous related party transactions and the need to raise capital .  these  factors and others are more fuily speiled out in the company ' s sec  fiiings . we urge you to read the filings before you invest . the rocket  stock  report does not represent that the information contained in this  message states ail materia | facts or does not omit a material fact  necessary  to make the statements therein not misleading . ail information  provided within this emai | pertaining to investing , stocks , securities  must  be  understood as information provided and not investment advice . the  rocket stock report advises all readers and subscribers to seek advice  from  a registered professiona | securities representative before deciding to  trade in stocks featured within this email . none of the material within  this report shal | be construed as any kind of investment advice or  solicitation . many of these companies are on the verge of bankruptcy .  you  can lose ail your money by investing in this stock . the publisher of  the rocket stock report is not a registered investment advisor .  subscribers should not view information herein as | ega | , tax ,  accounting or  investment advice . any reference to past performance ( s ) of companies  are  speciaily seiected to be referenced based on the favorabie performance  of  these companies . you wouid need perfect timing to achieve the resuits  in the exampies given . there can be no assurance of that happening .  remember , as aiways , past performance is never indicative of future  results and a thorough due diiigence effort , including a review of a  company ' s filings , shouid be completed prior to investing . in  compiiance  with the securities act of 1933 , section 17 ( b ) , the rocket stock report  discioses the receipt of tweive thousand doilars from a third party  ( gem , inc . ) , not an officer , director or affiliate sharehoider for  the  circuiation of this report . gem , inc . has a position in the stock  they  wil | se | | at any time without notice . be aware of an inherent confiict  of interest resuiting from such compensation due to the fact that this  is a paid advertisement and we are conflicted . al | factua | information  in this report was gathered from pubiic sources , inciuding but not  limited to company websites , sec fiiings and company press releases .  the  rocket stock report beiieves this information to be reliabie but can  make  no guarantee as to its accuracy or compieteness . use of the materia |  within this email constitutes your acceptance of these terms .\")\n",
        "\n",
        "# print(r)\n",
        "\n",
        "# flag = 0\n",
        "# for k in range(len(x)):\n",
        "#   try:\n",
        "#     embeding_bert.embed_text(x[k])\n",
        "#   except Exception as e:\n",
        "#     flag += 1\n",
        "    \n",
        "#     print(\"Broke \" + str(flag))\n",
        "\n",
        "# embed the list\n",
        "l = [embeding_bert.embed_text(x[i]) for i in range(0, len(x))]\n",
        "\n",
        "# stack the embeding vector to pass to k means\n",
        "l = tuple(l)\n",
        "encoded_x = torch.stack((l), dim=0)\n",
        "\n",
        "print(encoded_x.data)\n",
        "print(encoded_x.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-51c807fed021>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# embed the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membeding_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# stack the embeding vector to pass to k means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-51c807fed021>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# embed the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membeding_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# stack the embeding vector to pass to k means\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-1ac5983201e2>\u001b[0m in \u001b[0;36membed_text\u001b[0;34m(self, text_to_embed)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m       \u001b[0;31m# Evaluating the model will return a different number of objects based on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0;31m# how it's  configured in the `from_pretrained` call earlier. In this case,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 831\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m         )\n\u001b[1;32m    833\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (559) must match the size of tensor b (512) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic4phDATMf3F",
        "outputId": "f2a1410e-303a-4870-ab35-6a95b65434f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia3utEf9aYvi"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the sentences \n",
        "\n",
        "sim = (1 - cosine(et, et2)) * 100\n",
        "from kmeans_pytorch import kmeans\n",
        "print(\"The similarity is : %.2f\" % sim, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfGD4sGAQvwq",
        "outputId": "835dde5b-b16d-4a57-ec56-a5ed60c2f1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "from kmeans_pytorch import kmeans_predict\n",
        "\n",
        "ex = \"i dont like food\"\n",
        "ex = be.embed_text(ex)\n",
        "print(ex.shape)\n",
        "cluster_ids_y = kmeans_predict(\n",
        "    ex , cluster_centers, 'euclidean'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768])\n",
            "predicting on cpu..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-536d12395c05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m cluster_ids_y = kmeans_predict(\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mex\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kmeans_pytorch/__init__.py\u001b[0m in \u001b[0;36mkmeans_predict\u001b[0;34m(X, cluster_centers, distance, device)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distance_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mchoice_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchoice_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAVdpdfpQ5kG"
      },
      "source": [
        "plt.figure(figsize=(4, 3), dpi=160)\n",
        "plt.scatter(x[:, 0], x[:, 1], c=cluster_ids_x, cmap='cool')\n",
        "plt.scatter(y[:, 0], y[:, 1], c=cluster_ids_y, cmap='cool', marker='X')\n",
        "plt.scatter(\n",
        "    cluster_centers[:, 0], cluster_centers[:, 1],\n",
        "    c='white',\n",
        "    alpha=0.6,\n",
        "    edgecolors='black',\n",
        "    linewidths=2\n",
        ")\n",
        "plt.axis([-1, 1, -1, 1])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QZa4aBQ9wVR",
        "outputId": "2b958c73-eb43-47e4-db6a-41d349a7896d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "s1 = torch.empty(0,3)\n",
        "s2 = torch.tensor([4,5,6])\n",
        "s2 = torch.stack((s1,s2), dim=0)\n",
        "\n",
        "print(s2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-35cdfa216943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [0, 3] at entry 0 and [3] at entry 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfPSFW00c_ru",
        "outputId": "f9819a7c-5935-4870-a6ec-f349ca5f6dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "be = BertEmbeddings()\n",
        "import numpy  as np\n",
        "x1 = [\"I hate it\",\n",
        "     \"I really love to play cricket\",\n",
        "     \"This is very bad. You should kill him\", \n",
        "     \"This is awesome, I am looking to work\"]\n",
        "\n",
        "#encoded_x = be.embed_text(x[1])\n",
        "l1 = [be.embed_text(x1[i]) for i in range(0, len(x1))]\n",
        "print(len(l1))\n",
        "numy = np.array(l1)\n",
        "#print(encoded_x.shape)\n",
        "\n",
        "l1 = tuple(l1)\n",
        "encoded_x = torch.stack((l1), dim=0)\n",
        "print(encoded_x.data)\n",
        "print(encoded_x.shape)\n",
        "\n",
        "#et = be.embed_text(\"deposite money in a bank\")\n",
        "#et2 = be.embed_text(\"This is the best\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-fd70fc52d86c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnumy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(encoded_x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iryLo3xlBqdb",
        "outputId": "bc07251c-5c87-44c5-c61e-dc18b57c26ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(numy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-96b94dd58b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'numy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM2zS6aCegG3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}